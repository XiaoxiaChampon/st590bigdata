---
title: "ST590HW3"
author: "Xiaoxia Champon"
date: "September 16, 2016"
output: word_document
---

#1 
##-Suppose both drug A and B are designed to reduce blood pressure and they are being tested which one works better. The experiment will enroll 1200 patients with high fever to test Drug A or B. Assume that the subjects in this experiment include 600 men and 600 women with age ranging from 18 to 70. The primary outcome measure is the drop in blood pressure three hours after taking the treatment, which is the yardstick by which to measure the effectiveness of Drug A or B. The researchers randomly assign the 1200 subjects into two treatment groups, Group 1 (600 subjects taking Drug A) and Group 2 (600 subjects taking Drug B). The patients in the group don't know if they are taking Drug A or Drug B. Three hours after taking the treatments, the researchers compare the change in blood pressure between the treatment groups.  The dependent variable is the change in blood pressure under each treatment condition. If the Drug A is better, participants in the Group 1 should report significantly drop of blood pressure than participants under the Drug B condition. 
##- Mean drop of blood pressure of treatment A and B will be the estimate of interest. We assume that on average, extraneous factors will affect treatment conditions equally; so any significant differences between conditions can fairly be attributed to the independent variable. We also assume onsistency: The true outcome is the potential outcome; no unmeasured confounders: the treatment assignment is independent of the set of potential outcomes. The way the treatment is assigned will not affect the outcome;positivity: the probability that treatment is assgined to a subject is bigger than zero for all A,B. The blood pressure is measured under the same conditions with the same scale.
##-A possible analysis that could be used to compare the two drugs would be regression based estimator. Fit the observed data set with a linear model and using the model to predict the average drop of blood pressure under Drug A. Then predict the average drop of blood pressure under Drug B. Compare the mean of the predicted values using t-test and if the p-value is less than 0.5 then there's a difference between these two drugs. The higher the predicted average is, the better the drug is. It might lead to incorrect conclusions if the assumed model is not the correct model, ie: the correct model is not linear.


#2
### (a)If the assumed model is correct ie:true model is linear and assumed model is linear in this case, IPWE and AIPWE has better results compared with Regression-based estimator in this example.
```{r}
library(mvtnorm)
n = 100
covX = array(c(1,.3,.09, .3, 1, .3, .09, .3, 1), c(3,3))
B=10000    # number of Monte Carlo replications

meanYstara_1=rep(0,length=B)                                           
meanYstara_0=rep(0,length=B)                                          

muhatReg1=rep(0,length=B)
muhatReg0=rep(0,length=B)

IPWE1=rep(0,length=B)
IPWE0=rep(0,length=B)

AIPWE1=rep(0,length=B)
AIPWE0=rep(0,length=B)

Qhat= function(X, XA, a, regression){                   # Q function, takes data and linear model as input
  beta1hat = coef(regression)[1:4]                       # Specific to this choice of model
  beta2hat = coef(regression)[c(5, 9:11)]
  newX = cbind(rep(1, n), X)
  newXA = cbind(rep(1, n), XA)
  Q = newX %*% beta1hat + a * newXA %*% beta2hat
  return(Q)
}


IPWE = function(Y, A, phat, a){                             # Function works for any model
  pa = (phat^A * (1 - phat)^(1-A))
  muhata_IPWE = (1/n) * sum((Y * 1/pa)[A == a])
  return(muhata_IPWE)
}

AIPWE = function(Y, A, X, Xa, phat, Qhat, a){
  pa = (phat^A * (1 - phat)^(1-A))
  muhata_AIPWE = (1/n) * sum(Y * (A == a) / pa - ((A == a) - pa) / pa  * Qhat(X, Xa, rep(a, n), regression))
  return(muhata_AIPWE)
} 

for (b in 1:B){

X = rmvnorm(n = n, mean = c(1,1,1), sigma = covX) / 20    #Generate some covariates
XA = rmvnorm(n = n, mean = c(1,-1,-1), sigma = covX) / 5

beta1 = c(-2, 6, 1)
beta2 = c(.5, 2, -1)

expit = function(z){
  return(1/(1 + exp(-z)))
}

A = rbinom(n = n, size = 1, p = expit((XA %*% beta2)))   # Generate treatment dependent on covariates
mean(A)                                                  # Proportion assigned A
range(expit((XA %*% beta2)))                             # Check no assignment probabilities too close to 0 or 1


errors = rnorm(n)
Y = X %*% beta1 + A * XA %*% beta2 + errors              # Observed Ys
Ystara_1 = X %*% beta1 + XA %*% beta2 + errors           # Potential outcome if A = 1
Ystara_0 = X %*% beta1                                   # Potential outcome if A = 0


regression = lm(Y ~ X[,1] + X[,2] + X[,3] + A*XA[,1] + A * XA[,2] + A*XA[,3]) # Assumed model

logisticregression = glm(A ~ XA, family = binomial(link = "logit")) # Assumed model

phat = logisticregression$fitted.values


muhatReg1[b] = mean(Qhat(X, XA, rep(1, n), regression))     
muhatReg0[b] = mean(Qhat(X, XA, rep(0, n), regression))

IPWE1[b]=mean(IPWE(Y, A, phat,1) )
IPWE0[b]=mean(IPWE(Y, A, phat,0))
    
AIPWE1[b]=mean(AIPWE(Y,A,X,XA,phat,Qhat, 1) )    
AIPWE0[b]=mean(AIPWE(Y,A,X,XA,phat,Qhat, 0) )  

meanYstara_1[b]=mean(Ystara_1)                                        
meanYstara_0[b]=mean(Ystara_0)      
                                        
}

mean((meanYstara_0-muhatReg0)^2)
mean((meanYstara_1-muhatReg1)^2)

mean((meanYstara_0-IPWE0)^2)
mean((meanYstara_1-IPWE1)^2)

mean((meanYstara_0-AIPWE0)^2)
mean((meanYstara_1-AIPWE1)^2)
```

### (b)If the propencity score is misspecified, the mean of IPWE estimator and regression based estimator are very unstable compared with AIPWE.The MSE of AIPWE performs best among the three.
```{r}
library(mvtnorm)
n = 100
covX = array(c(1,.3,.09, .3, 1, .3, .09, .3, 1), c(3,3))
B=10000    # number of Monte Carlo replications

meanYstara_1=rep(0,length=B)                                           
meanYstara_0=rep(0,length=B)                                          

muhatReg1=rep(0,length=B)
muhatReg0=rep(0,length=B)

IPWE1=rep(0,length=B)
IPWE0=rep(0,length=B)

AIPWE1=rep(0,length=B)
AIPWE0=rep(0,length=B)

Qhat= function(X, XA, a, regression){                   # Q function, takes data and linear model as input
  beta1hat = coef(regression)[1:4]                       # Specific to this choice of model
  beta2hat = coef(regression)[c(5, 9:11)]
  newX = cbind(rep(1, n), X)
  newXA = cbind(rep(1, n), XA)
  Q = newX %*% beta1hat + a * newXA %*% beta2hat
  return(Q)
}


IPWE = function(Y, A, phat, a){                             # Function works for any model
  pa = (phat^A * (1 - phat)^(1-A))
  muhata_IPWE = (1/n) * sum((Y * 1/pa)[A == a])
  return(muhata_IPWE)
}

AIPWE = function(Y, A, X, Xa, phat, Qhat, a){
  pa = (phat^A * (1 - phat)^(1-A))
  muhata_AIPWE = (1/n) * sum(Y * (A == a) / pa - ((A == a) - pa) / pa  * Qhat(X, Xa, rep(a, n), regression))
  return(muhata_AIPWE)
} 

for (b in 1:B){

X = rmvnorm(n = n, mean = c(1,1,1), sigma = covX)/20     #Generate some covariates
XA = rmvnorm(n = n, mean = c(1,-1,-1), sigma = covX)
U = runif(n)
A = (U < .75) * ((XA %*% beta2)^2 < 1) + (U > .75)

mean(A)                                                  # Proportion assigned A
range(XA %*% beta2)                             # This lead to the wrong value of phat 

beta1 = c(-2, 6, 1)
beta2 = c(.5, 2, -1)

expit = function(z){
  return(1/(1 + exp(-z)))
}


errors = rnorm(n)
Y = X %*% beta1 + A * XA %*% beta2 + errors              # Observed Ys
Ystara_1 = X %*% beta1 + XA %*% beta2 + errors           # Potential outcome if A = 1
Ystara_0 = X %*% beta1                                   # Potential outcome if A = 0


regression = lm(Y ~ X[,1] + X[,2] + X[,3] + A*XA[,1] + A * XA[,2] + A*XA[,3]) # Assumed model

logisticregression = glm(A ~ XA, family = binomial(link = "logit")) # Assumed model

phat = logisticregression$fitted.values


muhatReg1[b] = mean(Qhat(X, XA, rep(1, n), regression))     
muhatReg0[b] = mean(Qhat(X, XA, rep(0, n), regression))

IPWE1[b]=mean(IPWE(Y, A, phat,1) )
IPWE0[b]=mean(IPWE(Y, A, phat,0))
    
AIPWE1[b]=mean(AIPWE(Y,A,X,XA,phat,Qhat, 1) )    
AIPWE0[b]=mean(AIPWE(Y,A,X,XA,phat,Qhat, 0) )  

meanYstara_1[b]=mean(Ystara_1)                                        
meanYstara_0[b]=mean(Ystara_0)      
                                        
}

head(meanYstara_1)

head(muhatReg1)

head(IPWE1)

head(AIPWE1)

mean((meanYstara_0-muhatReg0)^2)
mean((meanYstara_1-muhatReg1)^2)

mean((meanYstara_0-IPWE0)^2)
mean((meanYstara_1-IPWE1)^2)

mean((meanYstara_0-AIPWE0)^2)
mean((meanYstara_1-AIPWE1)^2)
```



### (c)If the Q function is misspecified, ie: true model is not linear, assumed model is linear, IPWE and AIPWE has better results compared with Regression-based estimator.
```{r}
library(mvtnorm)
n = 100
covX = array(c(1,.3,.09, .3, 1, .3, .09, .3, 1), c(3,3))
B=10000    # number of Monte Carlo replications

meanYstara_1=rep(0,length=B)                                           
meanYstara_0=rep(0,length=B)                                          

muhatReg1=rep(0,length=B)
muhatReg0=rep(0,length=B)

IPWE1=rep(0,length=B)
IPWE0=rep(0,length=B)

AIPWE1=rep(0,length=B)
AIPWE0=rep(0,length=B)

Qhat= function(X, XA, a, regression){                   # Q function, takes data and linear model as input
  beta1hat = coef(regression)[1:4]                       # Specific to this choice of model
  beta2hat = coef(regression)[c(5, 9:11)]
  newX = cbind(rep(1, n), X)
  newXA = cbind(rep(1, n), XA)
  Q = newX %*% beta1hat + a * newXA %*% beta2hat
  return(Q)
}


IPWE = function(Y, A, phat, a){                             # Function works for any model
  pa = (phat^A * (1 - phat)^(1-A))
  muhata_IPWE = (1/n) * sum((Y * 1/pa)[A == a])
  return(muhata_IPWE)
}

AIPWE = function(Y, A, X, Xa, phat, Qhat, a){
  pa = (phat^A * (1 - phat)^(1-A))
  muhata_AIPWE = (1/n) * sum(Y * (A == a) / pa - ((A == a) - pa) / pa  * Qhat(X, Xa, rep(a, n), regression))
  return(muhata_AIPWE)
} 


for (b in 1:B){

X = rmvnorm(n = n, mean = c(1,1,1), sigma = covX) / 20    #Generate some covariates
XA = rmvnorm(n = n, mean = c(1,-1,-1), sigma = covX) / 5

beta1 = c(-2, 6, 1)
beta2 = c(.5, 2, -1)

expit = function(z){
  return(1/(1 + exp(-z)))
}

A = rbinom(n = n, size = 1, p = expit((XA %*% beta2)))   # Generate treatment dependent on covariates
mean(A)                                                  # Proportion assigned A
range(expit((XA %*% beta2)))                             # Check no assignment probabilities too close to 0 or 1


errors = rnorm(n)
Y = cos(4 * (A-.5) * XA[,1] / (.5 - A * XA[,2]))  * (1 + errors)                # Observed Ys
Ystara_1 = cos(4 * (1-.5) * XA[,1] / (.5 - 1 * XA[,2])) * (1 + errors)          # Potential outcome if A = 1
Ystara_0 = cos(4 * (0-.5) * XA[,1] / (.5 - 0 * XA[,2])) * (1 + errors)          # Potential outcome if A = 0


regression = lm(Y ~ X[,1] + X[,2] + X[,3] + A*XA[,1] + A * XA[,2] + A*XA[,3]) # Assumed model

logisticregression = glm(A ~ XA, family = binomial(link = "logit")) # Assumed model

phat = logisticregression$fitted.values


muhatReg1[b] = mean(Qhat(X, XA, rep(1, n), regression))     
muhatReg0[b] = mean(Qhat(X, XA, rep(0, n), regression))

IPWE1[b]=mean(IPWE(Y, A, phat,1) )
IPWE0[b]=mean(IPWE(Y, A, phat,0))
    
AIPWE1[b]=mean(AIPWE(Y,A,X,XA,phat,Qhat, 1) )    
AIPWE0[b]=mean(AIPWE(Y,A,X,XA,phat,Qhat, 0) )  

meanYstara_1[b]=mean(Ystara_1)                                        
meanYstara_0[b]=mean(Ystara_0)      
                                        
}

mean((meanYstara_0-muhatReg0)^2)
mean((meanYstara_1-muhatReg1)^2)

mean((meanYstara_0-IPWE0)^2)
mean((meanYstara_1-IPWE1)^2)

mean((meanYstara_0-AIPWE0)^2)
mean((meanYstara_1-AIPWE1)^2)
```

#3 First of all, Cognitive behaviroal therapy can't be double-blind.
##-possible reason one: Team A is not good at conducting CBT and medication turns out to perform better in their study. Team B is expert of conducting CBT and CBT turns out to perform better.
##-possible reason two: Location of the samples are different. This affects the characterictics of the patients which leads to different reaction to medication and CBT even the sample is random.
##-possible reason three: measurement scale is different and it affects the variability of the results.

#4 Treatment 1 has better outcome based on two sample t-test results.
```{r}
trialdata=read.csv(file="C:\\Users\\Rob\\Downloads\\trialDataAnony.csv",sep=",",header=T)
str(trialdata)
set.seed(1)
library(randomForest)
regressionmodel=randomForest(outcome~.,data=trialdata,mtry=16,importance=TRUE)  ##use all predictors
varImpPlot(regressionmodel)
regressionmodel=randomForest(outcome~.+treatment*.,data=trialdata,mtry=8,importance=TRUE) ## For regression randomForest, use p/3 predictors. I used 8.
varImpPlot(regressionmodel)  ##Importance of the predictors variaies. So I include all the predictors in the model as well as the interaction terms.
data1=trialdata[,-c(16,17)]
treatment=rep(1,10000)
newdata1=data.frame(cbind(data1,treatment))
yhat1=predict(regressionmodel,newdata=newdata1)
treatment=rep(-1,10000)
newdatan1=data.frame(cbind(data1,treatment))
yhatn1=predict(regressionmodel,newdata=newdatan1)
mean(yhat1)
mean(yhatn1)
mean(subset(trialdata,treatment==1)$outcome)
mean(subset(trialdata,treatment==-1)$outcome)
t.test(yhat1,yhatn1)
```


## optimal regime: There are 8 times, we assign treatment -1 to the patients.
```{r}
pie=rep(1,10000)
for (i in 1:10000){
  if (yhat1[i]>yhatn1[i]){
    pie[i]=1
    i=i+1
  }
  else{
    pie[i]=-1
  }
  pie
}
table(pie)
which(yhat1<yhatn1)
```
#Extra credit: The value of the game at the start is 4.67: E(x)=2/6 [(5+6)/2] + 4/6 [4.25]=4.67
###Answer:Stage one, ie: After the first roll, if it's 5,6 (bigger than expected value 4.25) stop, otherwise continue. E(x)=.5*(4+5+6/3)+.5*3.5=4.25                        
### Stage 2, ie: after the 2nd roll, if it's 4,5,6 stop(bigger than the expected value 3.5), otherwise continue. E(x)=(1+2+3+4+5+6)/6=3.5
```{r}
probivnorm(2.2022,2.2022,sqrt(1/3))
```

